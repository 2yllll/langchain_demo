{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Lang Chain](https://python.langchain.com/en/latest/use_cases/code/code-analysis-deeplake.html)\n",
    "\n",
    "ç”¨ `Lang chain` / `Deep Lake` / `GPT` æ¥åˆ†æ `LangChain` åº“çš„æºç ã€‚\n",
    "\n",
    "**æ³¨ï¼š** [Deep Lake](https://www.deeplake.ai/) æ˜¯ä¸ª å‘é‡æ•°æ®åº“ (`Vector Database`)ï¼Œç±»ä¼¼äº [PineCone](https://www.pinecone.io/)\n",
    "\n",
    "æµç¨‹å¦‚ä¸‹ï¼š\n",
    "\n",
    "+ å‡†å¤‡æ•°æ®\n",
    "    - ç”¨ `TextLoader` ä¸Šä¼  Github LangChainåº“ æ‰€æœ‰çš„æºç æ–‡ä»¶ï¼Œæˆ‘ä»¬æŠŠè¿™äº›æ–‡ä»¶å« `document`\n",
    "    - ç”¨ `CharacterTextSplitter` åˆ†å‰² `document` æˆ å—(`chunk`)\n",
    "    - ç”¨ `OpenAIEmbedding` å°† `chunk` è½¬æ¢æˆ åµŒå…¥å‘é‡(`Embedding Vector`)ï¼Œå¹¶å°†å‘é‡ä¿å­˜åˆ° `Deep Lake`\n",
    "+ QA è®¾è®¡\n",
    "    - ç”¨ `ChatOpenAI` å’Œ `ConversationalRetrievalChain` æ„å»º ä¸€ä¸ª `Chain` \n",
    "    - é—® é—®é¢˜\n",
    "    - å¾—åˆ° ç­”æ¡ˆ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. å®‰è£…\n",
    "\n",
    "+ è¯·å®‰è£… `Python`ï¼›å¹¶åœ¨ `VsCode` ä¸Š å®‰è£… `Python`æ’ä»¶ï¼Œ`Jupyter` æ’ä»¶\n",
    "+ è¯·å‡†å¤‡å¥½ HTTP-ä»£ç†ï¼Œå¹¶ä¿è¯ VSCode èƒ½è®¿é—®è¯¥ä»£ç†ï¼›\n",
    "+ è¯·å‡†å¤‡å¥½ `OpenAI` çš„ `API Key`ï¼Œå°†å…¶é…åˆ°ä½ ä¸ªäººç”µè„‘çš„ç¯å¢ƒå˜é‡ `OPENAI_API_KEY` ä¸Šï¼›\n",
    "\n",
    "å®‰è£… ä¸‰ä¸ª python åº“ï¼š `langchain`, `deeplake`, `openai`\n",
    "\n",
    "``` bash\n",
    "pip3 install --upgrade langchain\n",
    "\n",
    "pip3 install --upgrade openai\n",
    "\n",
    "pip3 install --upgrade deeplake\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --upgrade langchain deeplake openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. ç”³è¯· Deep Lake\n",
    "\n",
    "Deep Lake æ˜¯ä¸ª å‘é‡æ•°æ®åº“\n",
    "\n",
    "+ åˆ° [è¿™é‡Œ](https://app.activeloop.ai/) æ³¨å†Œ è´¦å·ï¼Œå°†ä½ çš„è´¦å·åä¿®æ”¹ä¸‹é¢çš„ `DEEPLAKE_ACCOUNT_NAME`\n",
    "+ ç”³è¯· api-keyï¼Œå¹¶ å°† api-key å¡«åˆ° ç³»ç»Ÿç¯å¢ƒå˜é‡ `ACTIVELOOP_TOKEN`\n",
    "+ è¿è¡Œä¸‹é¢çš„å‘½ä»¤è¡Œï¼š\n",
    "\n",
    "``` bash\n",
    "activeloop login -t ä½ ç”³è¯·åˆ°çš„ACTIVELOOP_TOKEN\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ³¨ï¼šè¿™é‡Œè¦ç”¨ä½ çš„ ç”³è¯·è´¦å·\n",
    "DEEPLAKE_ACCOUNT_NAME = \"XXX\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™é‡Œè¦ç¡®ä¿`LangChain`çš„ç‰ˆæœ¬æ˜¯ 0.0.188 æˆ–ä»¥ä¸Šï¼›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.188'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "\n",
    "# ä¿è¯langchain ç”¨çš„ æ˜¯ æœ€æ–°çš„ 0.0.188 ç‰ˆæœ¬ï¼›\n",
    "\n",
    "langchain.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. åŠ è½½æ–‡ä»¶\n",
    "\n",
    "åŠ è½½æ–‡ä»¶ï¼š\n",
    "\n",
    "å®ç°å…ˆå°† langchain github åº“ git clone åˆ° æœ¬åœ°ï¼š\n",
    "\n",
    "``` bash\n",
    "git clone https://github.com/hwchase17/langchain.git\n",
    "```\n",
    "\n",
    "æ²¡æœ‰å®‰è£… git çš„ç«¥é‹ï¼Œå¯ä»¥ ç‚¹å‡» [è¿™é‡Œ](https://codeload.github.com/hwchase17/langchain/zip/refs/heads/master) ä¸‹è½½ zip å¹¶è§£å‹\n",
    "\n",
    "ç”¨ Lang Chain çš„ å·¥å…·ç±» `TextLoader` å°†æ–‡ä»¶ å˜ document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·²åŠ è½½ Python æ–‡ä»¶ 1565 ä¸ª\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content='\"\"\"Configuration file for the Sphinx documentation builder.\"\"\"\\n# Configuration file for the Sphinx documentation builder.\\n#\\n# This file only contains a selection of the most common options. For a full\\n# list see the documentation:\\n# https://www.sphinx-doc.org/en/master/usage/configuration.html\\n\\n# -- Path setup --------------------------------------------------------------\\n\\n# If extensions (or modules to document with autodoc) are in another directory,\\n# add these directories to sys.path here. If the directory is relative to the\\n# documentation root, use os.path.abspath to make it absolute, like shown here.\\n#\\n# import os\\n# import sys\\n# sys.path.insert(0, os.path.abspath(\\'.\\'))\\n\\nimport toml\\n\\nwith open(\"../pyproject.toml\") as f:\\n    data = toml.load(f)\\n\\n# -- Project information -----------------------------------------------------\\n\\nproject = \"ğŸ¦œğŸ”— LangChain\"\\ncopyright = \"2023, Harrison Chase\"\\nauthor = \"Harrison Chase\"\\n\\nversion = data[\"tool\"][\"poetry\"][\"version\"]\\nrelease = version\\n\\nhtml_title = project + \" \" + version\\nhtml_last_updated_fmt = \"%b %d, %Y\"\\n\\n\\n# -- General configuration ---------------------------------------------------\\n\\n# Add any Sphinx extension module names here, as strings. They can be\\n# extensions coming with Sphinx (named \\'sphinx.ext.*\\') or your custom\\n# ones.\\nextensions = [\\n    \"sphinx.ext.autodoc\",\\n    \"sphinx.ext.autodoc.typehints\",\\n    \"sphinx.ext.autosummary\",\\n    \"sphinx.ext.napoleon\",\\n    \"sphinx.ext.viewcode\",\\n    \"sphinxcontrib.autodoc_pydantic\",\\n    \"myst_nb\",\\n    \"sphinx_copybutton\",\\n    \"sphinx_panels\",\\n    \"IPython.sphinxext.ipython_console_highlighting\",\\n]\\nsource_suffix = [\".ipynb\", \".html\", \".md\", \".rst\"]\\n\\nautodoc_pydantic_model_show_json = False\\nautodoc_pydantic_field_list_validators = False\\nautodoc_pydantic_config_members = False\\nautodoc_pydantic_model_show_config_summary = False\\nautodoc_pydantic_model_show_validator_members = False\\nautodoc_pydantic_model_show_field_summary = False\\nautodoc_pydantic_model_members = False\\nautodoc_pydantic_model_undoc_members = False\\n# autodoc_typehints = \"signature\"\\n# autodoc_typehints = \"description\"\\n\\n# Add any paths that contain templates here, relative to this directory.\\ntemplates_path = [\"_templates\"]\\n\\n# List of patterns, relative to source directory, that match files and\\n# directories to ignore when looking for source files.\\n# This pattern also affects html_static_path and html_extra_path.\\nexclude_patterns = [\"_build\", \"Thumbs.db\", \".DS_Store\"]\\n\\n\\n# -- Options for HTML output -------------------------------------------------\\n\\n# The theme to use for HTML and HTML Help pages.  See the documentation for\\n# a list of builtin themes.\\n#\\nhtml_theme = \"sphinx_book_theme\"\\n\\nhtml_theme_options = {\\n    \"path_to_docs\": \"docs\",\\n    \"repository_url\": \"https://github.com/hwchase17/langchain\",\\n    \"use_repository_button\": True,\\n}\\n\\nhtml_context = {\\n    \"display_github\": True,  # Integrate GitHub\\n    \"github_user\": \"hwchase17\",  # Username\\n    \"github_repo\": \"langchain\",  # Repo name\\n    \"github_version\": \"master\",  # Version\\n    \"conf_py_path\": \"/docs/\",  # Path in the checkout to the docs root\\n}\\n\\n# Add any paths that contain custom static files (such as style sheets) here,\\n# relative to this directory. They are copied after the builtin static files,\\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\\nhtml_static_path = [\"_static\"]\\n\\n# These paths are either relative to html_static_path\\n# or fully qualified paths (eg. https://...)\\nhtml_css_files = [\\n    \"css/custom.css\",\\n]\\n\\nhtml_js_files = [\\n    \"js/mendablesearch.js\",\\n]\\n\\nnb_execution_mode = \"off\"\\nmyst_enable_extensions = [\"colon_fence\"]', metadata={'source': './langchain/docs\\\\conf.py'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# LangChainåº“çš„æœ¬åœ° clone ç›®å½•\n",
    "root_dir = './langchain/'\n",
    "\n",
    "docs = []\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    for file in filenames:\n",
    "        # ä»…å¤„ç† Python æ–‡ä»¶\n",
    "        if file.endswith('.py') and '/.venv/' not in dirpath:\n",
    "            try: \n",
    "                loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')\n",
    "                \n",
    "                document_list = loader.load_and_split()\n",
    "\n",
    "                # å°† document_list flat åˆ° docs å»ï¼›\n",
    "                docs.extend(document_list)\n",
    "            except Exception as e: \n",
    "                pass\n",
    "\n",
    "print(f'å·²åŠ è½½ Python æ–‡ä»¶ {len(docs)} ä¸ª')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. åˆ†å‰²æ–‡ä»¶\n",
    "\n",
    "åˆ†å‰²æ–‡ä»¶ï¼šè¿™ä¸ªDemoç”¨åˆ°æ–‡æœ¬çš„æ–¹å¼åˆ†å‰²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1006, which is longer than the specified 1000\n",
      "Created a chunk of size 1213, which is longer than the specified 1000\n",
      "Created a chunk of size 1782, which is longer than the specified 1000\n",
      "Created a chunk of size 1620, which is longer than the specified 1000\n",
      "Created a chunk of size 1485, which is longer than the specified 1000\n",
      "Created a chunk of size 1919, which is longer than the specified 1000\n",
      "Created a chunk of size 3515, which is longer than the specified 1000\n",
      "Created a chunk of size 1852, which is longer than the specified 1000\n",
      "Created a chunk of size 1533, which is longer than the specified 1000\n",
      "Created a chunk of size 1331, which is longer than the specified 1000\n",
      "Created a chunk of size 2549, which is longer than the specified 1000\n",
      "Created a chunk of size 1696, which is longer than the specified 1000\n",
      "Created a chunk of size 1086, which is longer than the specified 1000\n",
      "Created a chunk of size 1647, which is longer than the specified 1000\n",
      "Created a chunk of size 1296, which is longer than the specified 1000\n",
      "Created a chunk of size 2005, which is longer than the specified 1000\n",
      "Created a chunk of size 1235, which is longer than the specified 1000\n",
      "Created a chunk of size 1221, which is longer than the specified 1000\n",
      "Created a chunk of size 1390, which is longer than the specified 1000\n",
      "Created a chunk of size 1300, which is longer than the specified 1000\n",
      "Created a chunk of size 1185, which is longer than the specified 1000\n",
      "Created a chunk of size 1453, which is longer than the specified 1000\n",
      "Created a chunk of size 1423, which is longer than the specified 1000\n",
      "Created a chunk of size 1036, which is longer than the specified 1000\n",
      "Created a chunk of size 1283, which is longer than the specified 1000\n",
      "Created a chunk of size 1045, which is longer than the specified 1000\n",
      "Created a chunk of size 1501, which is longer than the specified 1000\n",
      "Created a chunk of size 1208, which is longer than the specified 1000\n",
      "Created a chunk of size 1137, which is longer than the specified 1000\n",
      "Created a chunk of size 1176, which is longer than the specified 1000\n",
      "Created a chunk of size 1176, which is longer than the specified 1000\n",
      "Created a chunk of size 1219, which is longer than the specified 1000\n",
      "Created a chunk of size 1364, which is longer than the specified 1000\n",
      "Created a chunk of size 1212, which is longer than the specified 1000\n",
      "Created a chunk of size 1950, which is longer than the specified 1000\n",
      "Created a chunk of size 1414, which is longer than the specified 1000\n",
      "Created a chunk of size 1289, which is longer than the specified 1000\n",
      "Created a chunk of size 1029, which is longer than the specified 1000\n",
      "Created a chunk of size 1269, which is longer than the specified 1000\n",
      "Created a chunk of size 3173, which is longer than the specified 1000\n",
      "Created a chunk of size 1160, which is longer than the specified 1000\n",
      "Created a chunk of size 1058, which is longer than the specified 1000\n",
      "Created a chunk of size 1260, which is longer than the specified 1000\n",
      "Created a chunk of size 1195, which is longer than the specified 1000\n",
      "Created a chunk of size 2147, which is longer than the specified 1000\n",
      "Created a chunk of size 1183, which is longer than the specified 1000\n",
      "Created a chunk of size 1253, which is longer than the specified 1000\n",
      "Created a chunk of size 1411, which is longer than the specified 1000\n",
      "Created a chunk of size 1941, which is longer than the specified 1000\n",
      "Created a chunk of size 1061, which is longer than the specified 1000\n",
      "Created a chunk of size 1069, which is longer than the specified 1000\n",
      "Created a chunk of size 1848, which is longer than the specified 1000\n",
      "Created a chunk of size 1418, which is longer than the specified 1000\n",
      "Created a chunk of size 2573, which is longer than the specified 1000\n",
      "Created a chunk of size 1026, which is longer than the specified 1000\n",
      "Created a chunk of size 1030, which is longer than the specified 1000\n",
      "Created a chunk of size 1230, which is longer than the specified 1000\n",
      "Created a chunk of size 1226, which is longer than the specified 1000\n",
      "Created a chunk of size 1289, which is longer than the specified 1000\n",
      "Created a chunk of size 1224, which is longer than the specified 1000\n",
      "Created a chunk of size 1031, which is longer than the specified 1000\n",
      "Created a chunk of size 1999, which is longer than the specified 1000\n",
      "Created a chunk of size 1029, which is longer than the specified 1000\n",
      "Created a chunk of size 1077, which is longer than the specified 1000\n",
      "Created a chunk of size 1120, which is longer than the specified 1000\n",
      "Created a chunk of size 1033, which is longer than the specified 1000\n",
      "Created a chunk of size 1143, which is longer than the specified 1000\n",
      "Created a chunk of size 1416, which is longer than the specified 1000\n",
      "Created a chunk of size 2482, which is longer than the specified 1000\n",
      "Created a chunk of size 1019, which is longer than the specified 1000\n",
      "Created a chunk of size 1512, which is longer than the specified 1000\n",
      "Created a chunk of size 1262, which is longer than the specified 1000\n",
      "Created a chunk of size 1092, which is longer than the specified 1000\n",
      "Created a chunk of size 2175, which is longer than the specified 1000\n",
      "Created a chunk of size 1147, which is longer than the specified 1000\n",
      "Created a chunk of size 1096, which is longer than the specified 1000\n",
      "Created a chunk of size 1131, which is longer than the specified 1000\n",
      "Created a chunk of size 1227, which is longer than the specified 1000\n",
      "Created a chunk of size 1233, which is longer than the specified 1000\n",
      "Created a chunk of size 1250, which is longer than the specified 1000\n",
      "Created a chunk of size 1197, which is longer than the specified 1000\n",
      "Created a chunk of size 1168, which is longer than the specified 1000\n",
      "Created a chunk of size 1352, which is longer than the specified 1000\n",
      "Created a chunk of size 1098, which is longer than the specified 1000\n",
      "Created a chunk of size 1030, which is longer than the specified 1000\n",
      "Created a chunk of size 1504, which is longer than the specified 1000\n",
      "Created a chunk of size 1038, which is longer than the specified 1000\n",
      "Created a chunk of size 1140, which is longer than the specified 1000\n",
      "Created a chunk of size 1276, which is longer than the specified 1000\n",
      "Created a chunk of size 1300, which is longer than the specified 1000\n",
      "Created a chunk of size 1232, which is longer than the specified 1000\n",
      "Created a chunk of size 2108, which is longer than the specified 1000\n",
      "Created a chunk of size 1285, which is longer than the specified 1000\n",
      "Created a chunk of size 1221, which is longer than the specified 1000\n",
      "Created a chunk of size 1456, which is longer than the specified 1000\n",
      "Created a chunk of size 1181, which is longer than the specified 1000\n",
      "Created a chunk of size 1153, which is longer than the specified 1000\n",
      "Created a chunk of size 1075, which is longer than the specified 1000\n",
      "Created a chunk of size 1473, which is longer than the specified 1000\n",
      "Created a chunk of size 1058, which is longer than the specified 1000\n",
      "Created a chunk of size 1075, which is longer than the specified 1000\n",
      "Created a chunk of size 1236, which is longer than the specified 1000\n",
      "Created a chunk of size 1068, which is longer than the specified 1000\n",
      "Created a chunk of size 1318, which is longer than the specified 1000\n",
      "Created a chunk of size 1501, which is longer than the specified 1000\n",
      "Created a chunk of size 1197, which is longer than the specified 1000\n",
      "Created a chunk of size 1532, which is longer than the specified 1000\n",
      "Created a chunk of size 1535, which is longer than the specified 1000\n",
      "Created a chunk of size 1304, which is longer than the specified 1000\n",
      "Created a chunk of size 2248, which is longer than the specified 1000\n",
      "Created a chunk of size 1087, which is longer than the specified 1000\n",
      "Created a chunk of size 1096, which is longer than the specified 1000\n",
      "Created a chunk of size 2817, which is longer than the specified 1000\n",
      "Created a chunk of size 1589, which is longer than the specified 1000\n",
      "Created a chunk of size 1104, which is longer than the specified 1000\n",
      "Created a chunk of size 1449, which is longer than the specified 1000\n",
      "Created a chunk of size 1979, which is longer than the specified 1000\n",
      "Created a chunk of size 1681, which is longer than the specified 1000\n",
      "Created a chunk of size 1172, which is longer than the specified 1000\n",
      "Created a chunk of size 1237, which is longer than the specified 1000\n",
      "Created a chunk of size 1339, which is longer than the specified 1000\n",
      "Created a chunk of size 1228, which is longer than the specified 1000\n",
      "Created a chunk of size 1245, which is longer than the specified 1000\n",
      "Created a chunk of size 1061, which is longer than the specified 1000\n",
      "Created a chunk of size 2082, which is longer than the specified 1000\n",
      "Created a chunk of size 1224, which is longer than the specified 1000\n",
      "Created a chunk of size 2461, which is longer than the specified 1000\n",
      "Created a chunk of size 1583, which is longer than the specified 1000\n",
      "Created a chunk of size 1048, which is longer than the specified 1000\n",
      "Created a chunk of size 1052, which is longer than the specified 1000\n",
      "Created a chunk of size 1205, which is longer than the specified 1000\n",
      "Created a chunk of size 1104, which is longer than the specified 1000\n",
      "Created a chunk of size 1010, which is longer than the specified 1000\n",
      "Created a chunk of size 1247, which is longer than the specified 1000\n",
      "Created a chunk of size 1336, which is longer than the specified 1000\n",
      "Created a chunk of size 2622, which is longer than the specified 1000\n",
      "Created a chunk of size 1040, which is longer than the specified 1000\n",
      "Created a chunk of size 1497, which is longer than the specified 1000\n",
      "Created a chunk of size 1195, which is longer than the specified 1000\n",
      "Created a chunk of size 1056, which is longer than the specified 1000\n",
      "Created a chunk of size 1626, which is longer than the specified 1000\n",
      "Created a chunk of size 1148, which is longer than the specified 1000\n",
      "Created a chunk of size 1172, which is longer than the specified 1000\n",
      "Created a chunk of size 1623, which is longer than the specified 1000\n",
      "Created a chunk of size 1367, which is longer than the specified 1000\n",
      "Created a chunk of size 1353, which is longer than the specified 1000\n",
      "Created a chunk of size 1099, which is longer than the specified 1000\n",
      "Created a chunk of size 1473, which is longer than the specified 1000\n",
      "Created a chunk of size 1303, which is longer than the specified 1000\n",
      "Created a chunk of size 1017, which is longer than the specified 1000\n",
      "Created a chunk of size 1304, which is longer than the specified 1000\n",
      "Created a chunk of size 1362, which is longer than the specified 1000\n",
      "Created a chunk of size 1380, which is longer than the specified 1000\n",
      "Created a chunk of size 1021, which is longer than the specified 1000\n",
      "Created a chunk of size 1490, which is longer than the specified 1000\n",
      "Created a chunk of size 1506, which is longer than the specified 1000\n",
      "Created a chunk of size 1137, which is longer than the specified 1000\n",
      "Created a chunk of size 1134, which is longer than the specified 1000\n",
      "Created a chunk of size 1011, which is longer than the specified 1000\n",
      "Created a chunk of size 1039, which is longer than the specified 1000\n",
      "Created a chunk of size 1154, which is longer than the specified 1000\n",
      "Created a chunk of size 1249, which is longer than the specified 1000\n",
      "Created a chunk of size 1982, which is longer than the specified 1000\n",
      "Created a chunk of size 1542, which is longer than the specified 1000\n",
      "Created a chunk of size 2432, which is longer than the specified 1000\n",
      "Created a chunk of size 1289, which is longer than the specified 1000\n",
      "Created a chunk of size 1464, which is longer than the specified 1000\n",
      "Created a chunk of size 1310, which is longer than the specified 1000\n",
      "Created a chunk of size 1152, which is longer than the specified 1000\n",
      "Created a chunk of size 1012, which is longer than the specified 1000\n",
      "Created a chunk of size 1221, which is longer than the specified 1000\n",
      "Created a chunk of size 1176, which is longer than the specified 1000\n",
      "Created a chunk of size 1410, which is longer than the specified 1000\n",
      "Created a chunk of size 1335, which is longer than the specified 1000\n",
      "Created a chunk of size 1008, which is longer than the specified 1000\n",
      "Created a chunk of size 1111, which is longer than the specified 1000\n",
      "Created a chunk of size 1010, which is longer than the specified 1000\n",
      "Created a chunk of size 2101, which is longer than the specified 1000\n",
      "Created a chunk of size 1028, which is longer than the specified 1000\n",
      "Created a chunk of size 2321, which is longer than the specified 1000\n",
      "Created a chunk of size 2826, which is longer than the specified 1000\n",
      "Created a chunk of size 1186, which is longer than the specified 1000\n",
      "Created a chunk of size 1232, which is longer than the specified 1000\n",
      "Created a chunk of size 1075, which is longer than the specified 1000\n",
      "Created a chunk of size 1592, which is longer than the specified 1000\n",
      "Created a chunk of size 1375, which is longer than the specified 1000\n",
      "Created a chunk of size 3466, which is longer than the specified 1000\n",
      "Created a chunk of size 1208, which is longer than the specified 1000\n",
      "Created a chunk of size 1083, which is longer than the specified 1000\n",
      "Created a chunk of size 1074, which is longer than the specified 1000\n",
      "Created a chunk of size 1411, which is longer than the specified 1000\n",
      "Created a chunk of size 2300, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    "texts = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åˆ†å‰²æˆ 4765 ä¸ª chunk\n"
     ]
    }
   ],
   "source": [
    "print(f\"åˆ†å‰²æˆ {len(texts)} ä¸ª chunk\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. è¿›é˜¶ï¼šä»¥ä»£ç æ–¹å¼åˆ†å‰²\n",
    "\n",
    "ä½†æ˜¯ å¯ä»¥ä½¿ç”¨ [ä»£ç æ–¹å¼åˆ†å‰²](https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/code_splitter.html)ï¼Œç­‰åé¢ä¸€æ­¥å¯ä»¥ç»§ç»­å®éªŒï¼›\n",
    "\n",
    "+ æ³¨ï¼šLang Chain 0.0.188 ä»¥ä¸Šæ‰æœ‰ Language ç±»\n",
    "+ æ³¨ï¼šä»£ç æ–¹å¼ç›®å‰ä¸æ”¯æŒ C#ï¼Œä¸çŸ¥é“ä¸ºä»€ä¹ˆã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ³¨ï¼šlangchain 0.0.188 ä»¥ä¸Šæ‰æœ‰ Language ç±»\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    Language,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cpp',\n",
       " 'go',\n",
       " 'java',\n",
       " 'js',\n",
       " 'php',\n",
       " 'proto',\n",
       " 'python',\n",
       " 'rst',\n",
       " 'ruby',\n",
       " 'rust',\n",
       " 'scala',\n",
       " 'swift',\n",
       " 'markdown',\n",
       " 'latex',\n",
       " 'html']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ç›®å‰æ”¯æŒçš„ è¯­è¨€\n",
    "[e.value for e in Language]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RecursiveCharacterTextSplitter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# å¯ä»¥çœ‹åˆ° python è¯­è¨€ çš„ åˆ†å‰² ç¬¦å·\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m RecursiveCharacterTextSplitter\u001b[39m.\u001b[39mget_separators_for_language(Language\u001b[39m.\u001b[39mPYTHON)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RecursiveCharacterTextSplitter' is not defined"
     ]
    }
   ],
   "source": [
    "# å¯ä»¥çœ‹åˆ° python è¯­è¨€ çš„ åˆ†å‰² ç¬¦å·\n",
    "\n",
    "RecursiveCharacterTextSplitter.get_separators_for_language(Language.PYTHON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='def hello_world():\\n    print(\"Hello, World!\")', metadata={}),\n",
       " Document(page_content='# Call the function\\nhello_world()', metadata={})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PYTHON_CODE = \"\"\"\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "\n",
    "# Call the function\n",
    "hello_world()\n",
    "\"\"\"\n",
    "\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=50, chunk_overlap=0\n",
    ")\n",
    "\n",
    "python_docs = python_splitter.create_documents([PYTHON_CODE])\n",
    "\n",
    "python_docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. åµŒå…¥å‘é‡ å¹¶ä¸Šä¼ åˆ° Deep Leak\n",
    "\n",
    "+ è¿è¡Œçš„è¯ï¼Œéœ€è¦ç­‰å‡ åˆ†é’Ÿ\n",
    "+ è¯·åœ¨OpenAIçš„APIé¡¹é‡Œé¢ç»‘å®šå¥½å……å€¼çš„ä¿¡ç”¨å¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<class 'openai.api_resources.embedding.Embedding'>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=None, openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=6, request_timeout=None, headers=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(client=\"davinci\")\n",
    "\n",
    "embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n",
      "The dataset is private so make sure you are logged in!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/myy412001799/langchain-code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://myy412001799/langchain-code loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ingest: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:14<00:00\n",
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://myy412001799/langchain-code', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype      shape       dtype  compression\n",
      "  -------   -------    -------     -------  ------- \n",
      " embedding  generic  (4765, 1536)  float32   None   \n",
      "    ids      text     (4765, 1)      str     None   \n",
      " metadata    json     (4765, 1)      str     None   \n",
      "   text      text     (4765, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.deeplake.DeepLake at 0x1dc168e9390>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "db = DeepLake.from_documents(texts, embeddings, dataset_path=f\"hub://{DEEPLAKE_ACCOUNT_NAME}/langchain-code\")\n",
    "\n",
    "db"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. QA å›ç­”é—®é¢˜\n",
    "\n",
    "+ åŠ è½½æ•°æ®é›†\n",
    "+ æ„é€ æ£€ç´¢ retriever\n",
    "+ æ„é€  æ£€ç´¢é“¾ Conversational Chain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åŠ è½½ DeepLeak æ•°æ®åº“ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/myy412001799/langchain-code\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://myy412001799/langchain-code loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://myy412001799/langchain-code already exists, loading from the storage\n",
      "Dataset(path='hub://myy412001799/langchain-code', read_only=True, tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype      shape       dtype  compression\n",
      "  -------   -------    -------     -------  ------- \n",
      " embedding  generic  (4765, 1536)  float32   None   \n",
      "    ids      text     (4765, 1)      str     None   \n",
      " metadata    json     (4765, 1)      str     None   \n",
      "   text      text     (4765, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    }
   ],
   "source": [
    "# åŠ è½½æ•°æ®åº“\n",
    "\n",
    "db = DeepLake(\n",
    "    dataset_path=f\"hub://{DEEPLAKE_ACCOUNT_NAME}/langchain-code\", \n",
    "    read_only=True, \n",
    "    embedding_function=embeddings\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ„é€  æ£€ç´¢ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()\n",
    "\n",
    "retriever.search_kwargs['distance_metric'] = 'cos'\n",
    "retriever.search_kwargs['fetch_k'] = 20\n",
    "retriever.search_kwargs['maximal_marginal_relevance'] = True\n",
    "retriever.search_kwargs['k'] = 20"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿˜å¯ä»¥åˆ©ç”¨è¿‡æ»¤å™¨æ£€ç´¢ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(x):\n",
    "    # filter based on source code\n",
    "    if 'something' in x['text'].data()['value']:\n",
    "        return False\n",
    "    \n",
    "    # filter based on path e.g. extension\n",
    "    metadata =  x['metadata'].data()['value']\n",
    "    return 'only_this' in metadata['source'] or 'also_that' in metadata['source']\n",
    "\n",
    "### turn on below for custom filtering\n",
    "# retriever.search_kwargs['filter'] = filter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ„é€ æ£€ç´¢é“¾ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "model = ChatOpenAI(client=\"chatgpt\", model='gpt-3.5-turbo') # 'ada' 'gpt-3.5-turbo' 'gpt-4',\n",
    "qa = ConversationalRetrievalChain.from_llm(model,retriever=retriever)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é—®ç­”å¼€å§‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> **Question**: å“ªäº›ç±»ä»ç±»Chainä¸­æ´¾ç”Ÿ? \n",
      "\n",
      "**Answer**: ä»ç±»Chainä¸­æ´¾ç”Ÿçš„ç±»æœ‰ï¼š\n",
      "- APIChain\n",
      "- AnalyzeDocumentChain\n",
      "- BaseCombineDocumentsChain\n",
      "- BaseQAWithSourcesChain\n",
      "- ChatVectorDBChain\n",
      "- ConstitutionalChain\n",
      "- ConversationalRetrievalChain\n",
      "- ConversationChain\n",
      "- FlareChain\n",
      "- GraphCypherQAChain\n",
      "- GraphQAChain\n",
      "- HypotheticalDocumentEmbedder\n",
      "- LLMChain\n",
      "- LLMBashChain\n",
      "- LLMCheckerChain\n",
      "- LLMMathChain\n",
      "- LLMRequestsChain\n",
      "- LLMSummarizationCheckerChain\n",
      "- MapReduceChain\n",
      "- OpenAIModerationChain\n",
      "- PALChain\n",
      "- QAGenerationChain\n",
      "- QAWithSourcesChain\n",
      "- RetrievalQA\n",
      "- RetrievalQAWithSourcesChain\n",
      "- RouterChain\n",
      "- SequentialChain\n",
      "- SimpleSequentialChain\n",
      "- SQLDatabaseChain\n",
      "- SQLDatabaseSequentialChain\n",
      "- TransformChain\n",
      "- VectorDBQA\n",
      "- VectorDBQAWithSourcesChain \n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"å“ªäº›ç±»ä»ç±»Chainä¸­æ´¾ç”Ÿ?\",\n",
    "    # \"What classes are derived from the Chain class?\",\n",
    "    # \"What classes and functions in the ./langchain/utilities/ forlder are not covered by unit tests?\",\n",
    "    # \"What one improvement do you propose in code in relation to the class herarchy for the Chain class?\",\n",
    "] \n",
    "chat_history = []\n",
    "\n",
    "for question in questions:  \n",
    "    result = qa({\"question\": question, \"chat_history\": chat_history})\n",
    "    chat_history.append((question, result['answer']))\n",
    "    print(f\"-> **Question**: {question} \\n\")\n",
    "    print(f\"**Answer**: {result['answer']} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
