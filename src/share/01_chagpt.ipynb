{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGPT Demo\n",
    "\n",
    "用于展示 OpenAI 的 Chat-API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 准备工作\n",
    "\n",
    "1. 安装：Python 3.7+\n",
    "2. 安装 / 升级 Python 库: `openai`, `langchain`\n",
    "    - 命令行输入：`pip3 install --upgrade openai langchain`\n",
    "3. 设置 API Key: 放到 环境变量 `OPENAI_API_KEY` 里；\n",
    "\n",
    "**注：** `OpenAI` 要绑 信用卡 才能使用 API，见 [这里](./00_setup.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 版本 不能小于 3.7.0，当前版本为 3.10.10 | packaged by Anaconda, Inc. | (main, Mar 21 2023, 18:39:17) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(f\"python 版本 不能小于 3.7.0，当前版本为 {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai 版本不能小于 0.27.7，目前版本为:  0.27.7\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# 确认版本, openai 必须在 0.27.7 或以上\n",
    "print(\"openai 版本不能小于 0.27.7, 目前版本为: \", openai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain 版本不能小于 0.0.188, 目前版本为:  0.0.190\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "\n",
    "# 确认版本, langchain 必须在 0.0.188 或以上\n",
    "print(\"langchain 版本不能小于 0.0.188, 目前版本为: \", langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 记得安装openai package: pip3 install openai\n",
    "import openai\n",
    "\n",
    "# 事先将 OpenAI的 API-Key 存到 环境变量 'OPENAI_API_KEY' 里面\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. API 初步"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. role\n",
    "\n",
    "不管是 问问题，还是 gpt的回答，都有个 `role` 字段\n",
    "\n",
    "根据文档，目前 `role` 的值 有三个，分别代表三个角色：\n",
    "\n",
    "+ `user` 代表 用户角色\n",
    "+ `assistant` 代表 机器助手 角色\n",
    "+ `system` 代表 系统，就是 环境方面的提示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回复: 《春望》 - 唐代王之涣\n",
      "\n",
      "国破山河在，\n",
      "城春草木深。\n",
      "感时花溅泪，\n",
      "恨别鸟惊心。\n",
      "烽火连三月，\n",
      "家书抵万金。\n",
      "白头搔更短，\n",
      "浑欲不胜簪。\n"
     ]
    }
   ],
   "source": [
    "# 一条记录，这里是由用户询问的问题\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"你好，请说出一首唐诗\"\n",
    "}\n",
    "\n",
    "# ChatCompletion 是对话模型；\n",
    "response = openai.ChatCompletion.create(\n",
    "    # 如果帐号申请到了 gpt-4, 这里可以填 \"gpt-4\"\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    \n",
    "    # 这里填的是对话列表\n",
    "    messages=[message],\n",
    ")\n",
    "\n",
    "# 这里可以看到，回复是一个json对象，其中最重要的字段是它回复的答案，在这里：\n",
    "# response[\"choices\"] = [{\n",
    "#   \"message\": {\n",
    "#         \"content\": 回复的文本在这里\n",
    "#         \"role\": \"assistant\"\n",
    "#     }\n",
    "# }]\n",
    "answer = response['choices'][0]['message']['content']\n",
    "\n",
    "print(f\"回复: {answer}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. `Memory` 记忆\n",
    "\n",
    "因为 参数 `messages` 是个 列表 []，所以这里可以放多条记录；\n",
    "\n",
    "例子：可以和GPT聊天的历史记录串起来，形成一个有上下文的会话；\n",
    "\n",
    "这个历史记录，在 LangChain 里面成为 `Memory` (记忆)\n",
    "\n",
    "**注：** OpenAI 的 Chat API `没有状态`，每次通信都是独立的。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义 记忆："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory 记忆，代表对话历史\n",
    "memory = []\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面将一次问答封装成函数的形式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_answer(question):\n",
    "    \"\"\" 将 一问一答 封装成 函数，方便调用\n",
    "\n",
    "    注：这里没有处理各种异常情况，毕竟只是演示；\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # 一条记录，这里是由用户询问的问题\n",
    "    message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": question\n",
    "    }\n",
    "\n",
    "    # 将问题加入记忆\n",
    "    memory.append(message)\n",
    "\n",
    "    # ChatCompletion 是对话模型；\n",
    "    response = openai.ChatCompletion.create(\n",
    "        # 如果帐号申请到了 gpt-4, 这里可以填 \"gpt-4\"\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        \n",
    "        # 这里填的是 记忆\n",
    "        messages=memory,\n",
    "    )\n",
    "\n",
    "    reply = response['choices'][0]['message']\n",
    "\n",
    "    # 将回复加入记忆\n",
    "    memory.append({\n",
    "        \"content\": reply[\"content\"],\n",
    "        \"role\": reply[\"role\"],\n",
    "    })\n",
    "\n",
    "    answer = reply['content']\n",
    "\n",
    "    print(f\"问题：{question}\")\n",
    "    print(f\"回复: {answer}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用函数，形成对话："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题：你好，请说出一首唐诗\n",
      "回复: 《登鹳雀楼》\n",
      "白日依山尽，黄河入海流。\n",
      "欲窮千里目，更上一層樓。\n",
      "\n",
      "问题：它的作者是谁？有什么贡献？\n",
      "回复: 这首唐诗的作者是唐代著名诗人王之涣，他是唐代文学的代表人物之一，与杜甫、李白等被誉为“唐诗三杰”。王之涣的诗歌风格清新脱俗，富有哲理性和浪漫主义情怀，被后人称颂为“王家之风”。     \n",
      "\n",
      "《登鹳雀楼》是王之涣的代表作之一，这首诗主要描写了作者登上高楼远眺，眼界开阔，心情豁然，力主不断追求更高的境界。这首诗不仅表现了王之涣的历史性思考和人文主义情怀，同时也打破了唐诗以往平淡无奇的风格，开拓了唐诗的新领域，具有重要的艺术和时代意义。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simple_answer(\"你好，请说出一首唐诗\")\n",
    "\n",
    "simple_answer(\"它的作者是谁？有什么贡献？\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 其他参数\n",
    "\n",
    "上面的接口 除了 model 和 messages，还有一些有用的参数，下面展开：\n",
    "\n",
    "|参数名|说明|\n",
    "|--|--|\n",
    "|`model`|chat-模型，比如 \"gpt-3.5-turbo\", \"gpt-4\"|\n",
    "|`messages`|对话列表|\n",
    "|`max_tokens`|最大token数；对 3.5来说，该值不能超过 4K；|\n",
    "|`temperature`|温度 取值0到2的小数，数值越大，回复约随机|\n",
    "|`n`|该api回复问题的个数，写5，那么回复的messages就有5个候选答案|\n",
    "\n",
    "### 4.1. 关于 `token`\n",
    "\n",
    "+ 1 token 大概是 0.75个英文单词；\n",
    "+ 1个中文字 大概是 2个英文单词；\n",
    "\n",
    "上限：\n",
    "\n",
    "+ \"gpt-3.5-turbo\" 4K = 4096 tokens，包含 问答\n",
    "+ \"gpt-4\" 8K = 8192 tokens\n",
    "+ \"gpt-4-32\" 32K，目前 很难申请到\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面，将相关的参数封装成一个函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "memory = []\n",
    "\n",
    "def get_answer(question, debug=False, model=\"gpt-3.5-turbo\", n=1, max_tokens=1000, temperature=0.5):\n",
    "    \"\"\" 用 ChatGPT 回答问题\n",
    "\n",
    "    Args:\n",
    "        question (str): 问题\n",
    "        model (str, optional): 模型. Defaults to \"gpt-3.5-turbo\". 可以填 \"gpt-4\"\n",
    "        n (int, optional): 生成多少个候选答案. Defaults to 1.\n",
    "        max_tokens (int, optional): 限制不能超过多少个token. Defaults to 1000.\n",
    "        temperature (float, optional): 温度，值越大越随机，[0, 2] Defaults to 0.5.\n",
    "    \"\"\"\n",
    "\n",
    "    # 输入的每个元素，都是一个 对象\n",
    "    # \"role\" 有三种type: user, assistant, system\n",
    "    #     user 代表 用户输入的问题\n",
    "    #     assistant 代表 机器人回答的问题\n",
    "    #     system 代表 系统提示\n",
    "    record = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": question\n",
    "    }\n",
    "\n",
    "    # 历史 多加一条问题\n",
    "    memory.append(record)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"该次的输入参数: {memory}\")\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        # 必须\n",
    "        model=model,\n",
    "        # 这里填的是所有的历史\n",
    "        messages=memory,\n",
    "\n",
    "        # Optional\n",
    "        n=n,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "\n",
    "        presence_penalty=0,\n",
    "        frequency_penalty=0,\n",
    "        stream=False, # 是否用流式接口一个字一个字的返回\n",
    "    )\n",
    "\n",
    "    reply = response[\"choices\"][0][\"message\"]\n",
    "    \n",
    "    # 历史 多加一条答案\n",
    "    memory.append({\n",
    "        \"content\": reply[\"content\"],\n",
    "        \"role\": reply[\"role\"],\n",
    "    })\n",
    "\n",
    "    return reply[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "该次的输入参数: [{'role': 'user', 'content': '你好，请说出一首唐诗'}]\n",
      "\n",
      "问题：你好，请说出一首唐诗\n",
      "回复: 《登高》\n",
      "\n",
      "风急天高猿啸哀，渚清沙白鸟飞回。\n",
      "无边落木萧萧下，不尽长江滚滚来。\n",
      "万里悲秋常作客，百年多病独登台。\n",
      "艰难苦恨繁霜鬓，潦倒新停浊酒杯。\n",
      "\n",
      "该次的输入参数: [{'role': 'user', 'content': '你好，请说出一首唐诗'}, {'content': '《登高》\\n\\n风急天高猿啸哀，渚清沙白鸟飞回。\\n无边落木萧萧下，不尽长江滚滚来。\\n万里悲秋常作客，百年多病独登台。\\n艰难苦恨繁霜鬓，潦倒新停浊酒杯。', 'role': 'assistant'}, {'role': 'user', 'content': '请问它的作者是谁？'}]\n",
      "\n",
      "问题：请问它的作者是谁？\n",
      "回复: 这首诗的作者是唐代诗人杜甫。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "memory = []\n",
    "\n",
    "question = \"你好，请说出一首唐诗\"\n",
    "answer = get_answer(question, debug=True)\n",
    "\n",
    "print(\"\")\n",
    "print(f\"问题：{question}\")\n",
    "print(f\"回复: {answer}\")\n",
    "print(\"\")\n",
    "\n",
    "question = \"请问它的作者是谁？\"\n",
    "answer = get_answer(question, debug=True)\n",
    "\n",
    "print(\"\")\n",
    "print(f\"问题：{question}\")\n",
    "print(f\"回复: {answer}\")\n",
    "print(\"\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 再说 `role`\n",
    "\n",
    "经常听到 下面三个术语：\n",
    "\n",
    "+ `zero-shot prompt` 0-例子 提示\n",
    "+ `one-shot prompt`  1-例子 提示\n",
    "+ `few-shot prompt`  少数-例子 提示\n",
    "\n",
    "可以 通过 messages 的 role 完成的，完全可以在第一个问题之前，`伪造` 一些 机器回复的例子；\n",
    "\n",
    "这些概念，在 `LangChain`，被封装在 `Prompt Template` 的模块中\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们是上帝，为机器制造 先天记忆 ！\n",
    "memory = [{\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"这里，需要你扮演唐诗引导者的角色，对玩家的问题，要回答 你好，这是唐诗 ***，请欣赏: ***\"\n",
    "}, {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"你好，请说出一首唐诗\"\n",
    "}, {\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": '你好，这是唐诗《春晓》，请欣赏:\\n春眠不觉晓，处处闻啼鸟。\\n夜来风雨声，花落知多少。'\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "该次的输入参数: [{'role': 'system', 'content': '这里，需要你扮演唐诗引导者的角色，对玩家的问题，要回答 你好，这是唐诗 ***，请欣赏: ***'}, {'role': 'user', 'content': '你好，请说出一首唐诗'}, {'role': 'assistant', 'content': '你好，这是唐诗《春晓》，请欣赏:\\n春眠不觉晓，处处闻啼鸟。\\n夜来风雨声，花落知多少。'}, {'role': 'user', 'content': '你好，请说出一首唐诗'}]\n",
      "\n",
      "问题：你好，请说出一首唐诗\n",
      "回复: 你好，这是唐诗《登高》，请欣赏：\n",
      "风急天高猿啸哀，渚清沙白鸟飞回。\n",
      "无边落木萧萧下，不尽长江滚滚来。\n",
      "\n",
      "该次的输入参数: [{'role': 'system', 'content': '这里，需要你扮演唐诗引导者的角色，对玩家的问题，要回答 你好，这是唐诗 ***，请欣赏: ***'}, {'role': 'user', 'content': '你好，请说出一首唐诗'}, {'role': 'assistant', 'content': '你好，这是唐诗《春晓》，请欣赏:\\n春眠不觉晓，处处闻啼鸟。\\n夜来风雨声，花落知多少。'}, {'role': 'user', 'content': '你好，请说出一首唐诗'}, {'content': '你好，这是唐诗《登高》，请欣赏：\\n风急天高猿啸哀，渚清沙白鸟飞回。\\n无边落木萧萧下，不尽长江滚滚来。', 'role': 'assistant'}, {'role': 'user', 'content': '请问它的作者是谁？'}]\n",
      "\n",
      "问题：请问它的作者是谁？\n",
      "回复: 这首诗的作者是唐代著名诗人杜甫。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"你好，请说出一首唐诗\"\n",
    "answer = get_answer(question, debug=True)\n",
    "\n",
    "print(\"\")\n",
    "print(f\"问题：{question}\")\n",
    "print(f\"回复: {answer}\")\n",
    "print(\"\")\n",
    "\n",
    "question = \"请问它的作者是谁？\"\n",
    "answer = get_answer(question, debug=True)\n",
    "\n",
    "print(\"\")\n",
    "print(f\"问题：{question}\")\n",
    "print(f\"回复: {answer}\")\n",
    "print(\"\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 特点 & 问题\n",
    "\n",
    "### 6.1. 无状态\n",
    "\n",
    "需要 每次都要带 上下文（包括 对话历史 和 先验知识）\n",
    "\n",
    "如果你要为一本书回答问题，那么先验知识可能就是这本书的所有字符。\n",
    "\n",
    "因为API是按token收费的，这意味着几个问题之后，以后的每个问题都会按照最大token数收费了，在gpt-4单价昂贵的场景，是不利的。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. token 上限\n",
    "\n",
    "对 Turbo 3.5 模型，token上限是 4k = 4096个token\n",
    "\n",
    "复杂点的应用场景，既有历史记录，又有先验知识\n",
    "\n",
    "这意味着 连续为一本书问相关的几个问题，不管是前者还是后者，都放不下了。\n",
    "\n",
    "所以要引入 `嵌入式向量`，将`文本分块`，建`索引`，并将索引放到 `向量数据库`；每次问问题，就到数据库取和问题最相关的几条记录，并上最近的几个历史，传到 api 获得答案；\n",
    "\n",
    "这里：如果历史记录太多，那么历史记录本身就要建立索引；\n",
    "\n",
    "`LangChain` 的 `Index` 组件，封装了这个流程；\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. 通信限制\n",
    "\n",
    "OpenAI对 每个账号，有通信频率限制，不管是每分钟，还是每天总量都有限制，所以需要`调度`；\n",
    "\n",
    "`调度`策略，目前需要自己处理，但和LangChain 功能类似的 [`Simantic Kernel`](https://github.com/microsoft/semantic-kernel) 目前貌似封装了这个流程；\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. LangChain 概念一句话概括\n",
    "\n",
    "|组件|功能|其他|\n",
    "|--|--|--|\n",
    "|`Model`|封装 模型和参数||\n",
    "|`Prompt`|封装 提示模板，示例||\n",
    "|`Index`|封装 索引，存储||\n",
    "|`Memory`|封装 历史记录||\n",
    "|`Chain`|将上面各组件串成一个整体，方便使用||\n",
    "|`Agent`|智能体，和插件功能类似，见下文分解||"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
